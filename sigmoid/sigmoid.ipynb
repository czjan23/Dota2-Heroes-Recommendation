{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.optimizers import Adagrad,SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "with open('feature sigmoid.txt','r') as openFile:\n",
    "    for data in openFile:  \n",
    "        data = data.split()\n",
    "        temp = []\n",
    "        for d in data:\n",
    "            temp.append(int(d))\n",
    "        X.append(temp)\n",
    "with open('label sigmoid.txt','r') as openFile:\n",
    "    for data in openFile:  \n",
    "        Y.append(int(data))\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "\n",
    "\n",
    "feature_train,feature_test,label_train,label_test= train_test_split(X, Y, random_state=0,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95241 samples, validate on 31747 samples\n",
      "Epoch 1/30\n",
      "95241/95241 [==============================] - 8s 81us/step - loss: 0.7268 - val_loss: 0.6886\n",
      "Epoch 2/30\n",
      "95241/95241 [==============================] - 7s 74us/step - loss: 0.6776 - val_loss: 0.6874\n",
      "Epoch 3/30\n",
      "95241/95241 [==============================] - 7s 74us/step - loss: 0.6454 - val_loss: 0.7109\n",
      "Epoch 4/30\n",
      "95241/95241 [==============================] - 7s 69us/step - loss: 0.5718 - val_loss: 0.7925\n",
      "Epoch 5/30\n",
      "95241/95241 [==============================] - 7s 73us/step - loss: 0.4642 - val_loss: 0.8906\n",
      "Epoch 6/30\n",
      "95241/95241 [==============================] - 7s 75us/step - loss: 0.3295 - val_loss: 1.1236\n",
      "Epoch 7/30\n",
      "95241/95241 [==============================] - 7s 73us/step - loss: 0.1904 - val_loss: 1.3985\n",
      "Epoch 8/30\n",
      "95241/95241 [==============================] - 7s 72us/step - loss: 0.0917 - val_loss: 1.8371\n",
      "Epoch 9/30\n",
      "95241/95241 [==============================] - 7s 76us/step - loss: 0.0213 - val_loss: 2.3305\n",
      "Epoch 10/30\n",
      "95241/95241 [==============================] - 8s 80us/step - loss: 0.0073 - val_loss: 2.6293\n",
      "Epoch 11/30\n",
      "95241/95241 [==============================] - 8s 79us/step - loss: 0.0047 - val_loss: 2.8081\n",
      "Epoch 12/30\n",
      "95241/95241 [==============================] - 8s 82us/step - loss: 0.0039 - val_loss: 2.9054\n",
      "Epoch 13/30\n",
      "95241/95241 [==============================] - 8s 89us/step - loss: 0.0037 - val_loss: 2.9783\n",
      "Epoch 14/30\n",
      "95241/95241 [==============================] - 7s 75us/step - loss: 0.0036 - val_loss: 3.0031\n",
      "Epoch 15/30\n",
      "95241/95241 [==============================] - 7s 75us/step - loss: 0.0030 - val_loss: 3.1031\n",
      "Epoch 16/30\n",
      "95241/95241 [==============================] - 7s 74us/step - loss: 0.0027 - val_loss: 3.1572\n",
      "Epoch 17/30\n",
      "95241/95241 [==============================] - 7s 75us/step - loss: 0.0030 - val_loss: 3.1703\n",
      "Epoch 18/30\n",
      "95241/95241 [==============================] - 7s 72us/step - loss: 0.0024 - val_loss: 3.2079\n",
      "Epoch 19/30\n",
      "95241/95241 [==============================] - 9s 91us/step - loss: 0.0029 - val_loss: 3.2116\n",
      "Epoch 20/30\n",
      "95241/95241 [==============================] - 9s 91us/step - loss: 0.0023 - val_loss: 3.2390\n",
      "Epoch 21/30\n",
      "95241/95241 [==============================] - 9s 96us/step - loss: 0.0023 - val_loss: 3.2718\n",
      "Epoch 22/30\n",
      "95241/95241 [==============================] - 8s 83us/step - loss: 0.0023 - val_loss: 3.3173\n",
      "Epoch 23/30\n",
      "95241/95241 [==============================] - 8s 80us/step - loss: 0.0021 - val_loss: 3.3368\n",
      "Epoch 24/30\n",
      "95241/95241 [==============================] - 7s 77us/step - loss: 0.0018 - val_loss: 3.3680\n",
      "Epoch 25/30\n",
      "95241/95241 [==============================] - 7s 77us/step - loss: 0.0022 - val_loss: 3.3832\n",
      "Epoch 26/30\n",
      "95241/95241 [==============================] - 8s 81us/step - loss: 0.0020 - val_loss: 3.4056\n",
      "Epoch 27/30\n",
      "95241/95241 [==============================] - 8s 82us/step - loss: 0.0018 - val_loss: 3.4587\n",
      "Epoch 28/30\n",
      "95241/95241 [==============================] - 8s 84us/step - loss: 0.0016 - val_loss: 3.4715\n",
      "Epoch 29/30\n",
      "95241/95241 [==============================] - 8s 83us/step - loss: 0.0014 - val_loss: 3.5235\n",
      "Epoch 30/30\n",
      "95241/95241 [==============================] - 8s 84us/step - loss: 0.0015 - val_loss: 3.5245\n",
      "0.7783097615522726\n"
     ]
    }
   ],
   "source": [
    "loss_func = [\"binary_crossentropy\",\"mean_absolute_percentage_error\",\"mean_squared_error\",\"mean_absolute_error\"]\n",
    "opti= [\"Adagrad\"]\n",
    "activa = ['relu',\"linear\",\"tanh\",\"elu\",\"softplus\"]\n",
    "\n",
    "          \n",
    "model = Sequential()\n",
    "model.add(Dense(600,input_dim=234,activation='relu'))\n",
    "model.add(Dense(600,activation='relu'))\n",
    "model.add(Dense(600,activation='relu'))\n",
    "model.add(Dense(600,activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "epochs = 30\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adagrad')\n",
    "model.fit(feature_train, label_train, epochs=epochs, batch_size=500,verbose=1)\n",
    "\n",
    "            \n",
    "\n",
    "count = 0\n",
    "for i in range(len(feature_test)):\n",
    "    top = list(feature_test[i][0:117])\n",
    "    bot = list(feature_test[i][117:234])\n",
    "    test = []\n",
    "    test.append(list(feature_test[i]))#regular    \n",
    "    test.append(bot + top) #flip top and bot\n",
    "    test = np.array(test)\n",
    "    \n",
    "    prediction = model.predict(test) \n",
    "    radiant_win = (prediction[0] + 1-prediction[1])/2\n",
    "    \n",
    "    if(radiant_win > 0.5 and label_test[i] == 1):\n",
    "        count += 1\n",
    "    elif(radiant_win<=0.5 and label_test[i]==0):\n",
    "        count += 1   \n",
    "print(count/len(label_test))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sigmoid prediction.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
